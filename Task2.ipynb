{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12486024,"sourceType":"datasetVersion","datasetId":7878862},{"sourceId":13989132,"sourceType":"datasetVersion","datasetId":8916428},{"sourceId":14239386,"sourceType":"datasetVersion","datasetId":9084695}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y tensorboard protobuf\n!pip install protobuf==3.20.3 tensorboard==2.13.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T21:19:17.416000Z","iopub.execute_input":"2025-12-20T21:19:17.416670Z","iopub.status.idle":"2025-12-20T21:22:40.903832Z","shell.execute_reply.started":"2025-12-20T21:19:17.416644Z","shell.execute_reply":"2025-12-20T21:22:40.902890Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: tensorboard 2.18.0\nUninstalling tensorboard-2.18.0:\n  Successfully uninstalled tensorboard-2.18.0\nFound existing installation: protobuf 6.33.0\nUninstalling protobuf-6.33.0:\n  Successfully uninstalled protobuf-6.33.0\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc6ca94fc10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc6ca850e50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc6ca852450>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc6ca8c4590>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc6ca8632d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/protobuf/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement protobuf==3.20.3 (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for protobuf==3.20.3\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================\n# CTR MODEL - ARCHITECTURE EXACTE\n# [Embeddings] ‚Üí [Transformer] ‚Üí [Concat avec features] ‚Üí [DCNv2 + DNN parall√®le] ‚Üí [MLP final]\n#                     ‚îÇ\n#                     ‚îî‚îÄ‚Üí [Sequence + Target] dans Transformer\n# ============================================\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nimport numpy as np\nfrom typing import List, Dict\nimport pytorch_lightning as pl\n\n# ==================== CONFIGURATION ====================\nclass Config:\n    # Data\n    MAX_SEQ_LEN = 100\n    MAX_TAG_LEN = 10\n    \n    # Model dimensions\n    EMBEDDING_DIM = 64  # UNIFORME pour toutes les embeddings\n    ITEM_EMB_DIM = 128  # Dimension des embeddings d'items\n    \n    # Transformer\n    TRANSFORMER_HEADS = 2      # 1 t√™te seulement\n    TRANSFORMER_LAYERS = 4\n    DIM_FEEDFORWARD = 256\n    TRANSFORMER_DROPOUT = 0.2\n    \n    # DCN\n    DCN_LAYERS = 3\n    DCN_LOW_RANK = 64\n    \n    # DNN\n    DNN_HIDDEN = [1024, 512, 256]  # Comme solution gagnante\n    MLP_HIDDEN = [64, 32]          # Comme solution gagnante\n    \n    # Features extraction\n    FIRST_K_COLS = 16     # Prendre les 16 derni√®res colonnes\n    CONCAT_MAX_POOL = True  # Ajouter max pooling\n    \n    # Training\n    LR = 5e-4\n    EPOCHS = 7\n    \n    # Vocab sizes (doivent correspondre √† vos donn√©es)\n    NUM_TAGS = 11740 + 1000\n    LIKES_VOCAB = 11 + 5      # 0-10\n    VIEWS_VOCAB = 11 + 5      # 0-10\n\n# ==================== MOD√àLE PRINCIPAL ====================\nclass ExactCTRModel(nn.Module):\n    \"\"\"\n    Architecture EXACTE :\n    1. Embeddings uniformes\n    2. Transformer(items + target SEULEMENT)\n    3. Concat avec autres features\n    4. DCNv2 + DNN parall√®le\n    5. MLP final\n    \"\"\"\n    \n    def __init__(self, item_dim: int, num_users: int, config: Config = Config()):\n        super().__init__()\n        self.config = config\n        \n        # ========== 1. EMBEDDINGS UNIFORMES ==========\n        self.user_embedding = nn.Embedding(num_users + 100, config.EMBEDDING_DIM, padding_idx=0)\n        self.tag_embedding = nn.Embedding(config.NUM_TAGS + 100, config.EMBEDDING_DIM, padding_idx=0)\n        self.likes_embedding = nn.Embedding(config.LIKES_VOCAB + 10, config.EMBEDDING_DIM, padding_idx=0)\n        self.views_embedding = nn.Embedding(config.VIEWS_VOCAB + 10, config.EMBEDDING_DIM, padding_idx=0)\n        \n        # Dropout l√©ger pour embeddings\n        self.emb_dropout = nn.Dropout(0.1)\n        # Geler les embeddings (les rendre non-entra√Ænables)\n        for emb in [self.user_embedding, self.tag_embedding, self.likes_embedding, self.views_embedding]:\n            for param in emb.parameters():\n                param.requires_grad = False\n\n        \n        # ========== 2. TRANSFORMER (ITEMS + TARGET SEULEMENT) ==========\n        # Input: concat(item_emb, target_emb) = item_dim * 2\n        transformer_input_dim = item_dim * 2\n        \n        self.transformer = TransformerEncoder(\n            TransformerEncoderLayer(\n                d_model=transformer_input_dim,\n                nhead=config.TRANSFORMER_HEADS,\n                dim_feedforward=config.DIM_FEEDFORWARD,\n                dropout=config.TRANSFORMER_DROPOUT,\n                batch_first=True,\n                activation='relu'  # Exactement relu\n            ),\n            num_layers=config.TRANSFORMER_LAYERS\n        )\n        \n        # ========== 3. CALCUL DES DIMENSIONS ==========\n        # Dimension de sortie du transformer\n        transformer_out_dim = self._get_transformer_output_dim(item_dim)\n        \n        # Dimension d'entr√©e pour DCN\n        self.dcn_input_dim = (\n            config.EMBEDDING_DIM * 4 +  # user + tags + likes + views\n            2 +                         # numerics (likes_norm, views_norm)\n            item_dim +                  # target original\n            transformer_out_dim         # transformer output\n        )\n        \n        # ========== 4. DCNv2 SIMPLE ==========\n        self.dcn_layers, self.dcn_identities = self._build_dcn()\n        \n        # ========== 5. DNN PARALL√àLE ==========\n        self.parallel_dnn = self._build_parallel_dnn()\n        \n        # ========== 6. MLP FINAL ==========\n        self.final_mlp = self._build_final_mlp()\n        \n        # Initialisation\n        self._init_weights()\n    \n    def _get_transformer_output_dim(self, item_dim: int) -> int:\n        \"\"\"Calcule la dimension de sortie du transformer\"\"\"\n        transformer_input_dim = item_dim * 2\n        transformer_out_dim = self.config.FIRST_K_COLS * transformer_input_dim\n        \n        if self.config.CONCAT_MAX_POOL:\n            transformer_out_dim += transformer_input_dim\n            \n        return transformer_out_dim\n    \n    def _build_dcn(self) -> nn.Module:\n        \"\"\"Construit le DCNv2 simple\"\"\"\n        layers = []\n        x0_identity = []  # Pour garder x0\n        \n        for i in range(self.config.DCN_LAYERS):\n            # Low-rank transformation: U et V\n            U = nn.Linear(self.dcn_input_dim, self.config.DCN_LOW_RANK, bias=False)\n            V = nn.Linear(self.config.DCN_LOW_RANK, self.dcn_input_dim)\n            \n            # Gating mechanism\n            gate = nn.Linear(self.dcn_input_dim, self.dcn_input_dim)\n            \n            layers.append(nn.ModuleDict({\n                'U': U,\n                'V': V,\n                'gate': gate\n            }))\n            x0_identity.append(nn.Identity())  # Pour garder x0\n        \n        return nn.ModuleList(layers), nn.ModuleList(x0_identity)\n    \n    def _build_parallel_dnn(self) -> nn.Sequential:\n        \"\"\"Construit le DNN parall√®le\"\"\"\n        layers = []\n        input_dim = self.dcn_input_dim\n        \n        for hidden_dim in self.config.DNN_HIDDEN:\n            layers.extend([\n                nn.Linear(input_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Dropout(0.2)\n            ])\n            input_dim = hidden_dim\n        \n        return nn.Sequential(*layers)\n    \n    def _build_final_mlp(self) -> nn.Sequential:\n        \"\"\"Construit le MLP final\"\"\"\n        # Input: dcn_output + dnn_output\n        final_input_dim = self.dcn_input_dim + self.config.DNN_HIDDEN[-1]\n        \n        layers = []\n        input_dim = final_input_dim\n        \n        for hidden_dim in self.config.MLP_HIDDEN:\n            layers.extend([\n                nn.Linear(input_dim, hidden_dim),\n                nn.ReLU(),\n                nn.Dropout(0.2)\n            ])\n            input_dim = hidden_dim\n        \n        # Couche de sortie\n        layers.append(nn.Linear(input_dim, 1))\n        \n        return nn.Sequential(*layers)\n    \n    def _init_weights(self):\n        \"\"\"Initialisation simple des poids\"\"\"\n        for name, module in self.named_modules():\n            if isinstance(module, nn.Linear):\n                if 'final' in name or 'output' in name:\n                    nn.init.xavier_uniform_(module.weight, gain=0.01)\n                else:\n                    nn.init.xavier_uniform_(module.weight, gain=1.0)\n                \n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n            \n            elif isinstance(module, nn.Embedding):\n                nn.init.normal_(module.weight, mean=0, std=0.01)\n    \n    def forward(self, \n                tgt_vec: torch.Tensor,      # [B, item_dim]\n                seq_vecs: torch.Tensor,     # [B, seq_len, item_dim]\n                seq_mask: torch.Tensor,     # [B, seq_len]\n                numerics: torch.Tensor,     # [B, 2] (likes_norm, views_norm)\n                user_ids: torch.Tensor,     # [B]\n                tag_ids: torch.Tensor,      # [B, max_tags]\n                tag_mask: torch.Tensor,     # [B, max_tags]\n                likes: torch.Tensor,        # [B]\n                views: torch.Tensor         # [B]\n               ) -> torch.Tensor:\n        \"\"\"\n        Forward EXACTEMENT selon l'architecture :\n        1. Embeddings\n        2. Transformer(items + target)\n        3. Concat avec autres features\n        4. DCNv2 + DNN parall√®le\n        5. MLP final\n        \"\"\"\n        batch_size, seq_len, item_dim = seq_vecs.shape\n        \n        # ========== 1. EMBEDDINGS SIMPLES ==========\n        user_emb = self.emb_dropout(self.user_embedding(user_ids))          # [B, D]\n        \n        # Tags: simple mean pooling\n        tag_emb = self.emb_dropout(self.tag_embedding(tag_ids))            # [B, max_tags, D]\n        tag_mask_expanded = tag_mask.unsqueeze(-1).float()                 # [B, max_tags, 1]\n        tag_repr = (tag_emb * tag_mask_expanded).sum(dim=1)                # [B, D]\n        tag_repr = tag_repr / tag_mask.sum(dim=1, keepdim=True).clamp(min=1)  # [B, D]\n        likes = likes.clamp(0, self.likes_embedding.num_embeddings - 1)\n        views = views.clamp(0, self.views_embedding.num_embeddings - 1)\n\n        likes_emb = self.emb_dropout(self.likes_embedding(likes))\n        views_emb = self.emb_dropout(self.views_embedding(views))\n\n                  # [B, D]\n                 # [B, D]\n        \n        # ========== 2. TRANSFORMER (ITEMS + TARGET SEULEMENT) ==========\n        # Expansion du target pour chaque position de s√©quence\n        tgt_expanded = tgt_vec.unsqueeze(1).expand(-1, seq_len, -1)        # [B, seq_len, item_dim]\n        \n        # Concat√©nation: items + target (SEULEMENT ces deux!)\n        transformer_input = torch.cat([seq_vecs, tgt_expanded], dim=-1)    # [B, seq_len, item_dim*2]\n        \n        # Transformer\n        transformer_out = self.transformer(\n            src=transformer_input,\n            src_key_padding_mask=~seq_mask\n        )                                                                  # [B, seq_len, item_dim*2]\n        \n        # ========== 3. EXTRACTION DES FEATURES DU TRANSFORMER ==========\n        features_list = []\n        \n        # a) First K columns\n        first_k_features = transformer_out[:, -self.config.FIRST_K_COLS:, :]  # [B, K, item_dim*2]\n        first_k_features = first_k_features.flatten(start_dim=1)              # [B, K * item_dim*2]\n        features_list.append(first_k_features)\n        \n        # b) Max pooling (optionnel)\n        if self.config.CONCAT_MAX_POOL:\n            # Mask pour max pooling\n            transformer_masked = transformer_out.masked_fill(\n                ~seq_mask.unsqueeze(-1), \n                float('-inf')\n            )\n            max_pooled = transformer_masked.max(dim=1).values                # [B, item_dim*2]\n            features_list.append(max_pooled)\n        \n        # Concat√©nation des features du transformer\n        transformer_features = torch.cat(features_list, dim=1)              # [B, transformer_out_dim]\n        \n        # ========== 4. CONCAT√âNATION AVEC AUTRES FEATURES ==========\n        # Ordre EXACT: transformer ‚Üí user ‚Üí tags ‚Üí likes ‚Üí views ‚Üí numerics ‚Üí target\n        dcn_input = torch.cat([\n            transformer_features,  # [B, transformer_out_dim]\n            user_emb,              # [B, D]\n            tag_repr,              # [B, D]\n            likes_emb,             # [B, D]\n            views_emb,             # [B, D]\n            numerics,              # [B, 2]\n            tgt_vec                # [B, item_dim]\n        ], dim=1)                                                          # [B, dcn_input_dim]\n        \n        # ========== 5. DCNv2 ==========\n        dcn_layers, x0_identity = self.dcn_layers, self.dcn_identities\n        x0 = dcn_input  # Sauvegarde de l'input original\n        \n        for i, layer in enumerate(dcn_layers):\n            # Garder x0 pour cette couche\n            x0_i = x0_identity[i](x0)\n            \n            # Low-rank transformation\n            u = layer['U'](dcn_input)                    # [B, low_rank]\n            v = layer['V'](u)                            # [B, dcn_input_dim]\n            \n            # Gating\n            gate = torch.sigmoid(layer['gate'](dcn_input))  # [B, dcn_input_dim]\n            \n            # Interaction cross\n            cross = gate * (x0_i * v)                     # [B, dcn_input_dim]\n            \n            # Residual connection\n            dcn_input = dcn_input + cross\n        \n        dcn_output = dcn_input  # [B, dcn_input_dim]\n        \n        # ========== 6. DNN PARALL√àLE ==========\n        dnn_output = self.parallel_dnn(x0)                # [B, DNN_HIDDEN[-1]]\n        \n        # ========== 7. MLP FINAL ==========\n        # Concat√©nation: dcn_output + dnn_output\n        final_input = torch.cat([dcn_output, dnn_output], dim=1)  # [B, dcn_input_dim + DNN_HIDDEN[-1]]\n        \n        # Pr√©diction finale\n        logits = self.final_mlp(final_input).squeeze(-1)  # [B]\n        \n        return logits\n###################\nclass CTRLightningModule(pl.LightningModule):\n    \"\"\"Module Lightning avec s√©curit√© des indices\"\"\"\n    \n    def __init__(self, model: nn.Module, learning_rate: float = Config.LR):\n        super().__init__()\n        self.model = model\n        self.learning_rate = learning_rate\n        \n        # Loss function\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n        # Pour le monitoring\n        self.val_targets = []\n        self.val_preds = []\n        \n        self.save_hyperparameters(ignore=['model'])\n    \n    def safe_forward(self, batch):\n        \"\"\"Forward avec s√©curit√© des indices\"\"\"\n        # Extraire les tailles d'embeddings du mod√®le\n        user_emb_size = self.model.user_embedding.num_embeddings\n        tag_emb_size = self.model.tag_embedding.num_embeddings\n        likes_emb_size = self.model.likes_embedding.num_embeddings\n        views_emb_size = self.model.views_embedding.num_embeddings\n        \n        # Clamp s√©curitaire\n        batch['user_ids'] = torch.clamp(batch['user_ids'], 0, user_emb_size - 1)\n        batch['tag_ids'] = torch.clamp(batch['tag_ids'], 0, tag_emb_size - 1)\n        batch['likes'] = torch.clamp(batch['likes'], 0, likes_emb_size - 1)\n        batch['views'] = torch.clamp(batch['views'], 0, views_emb_size - 1)\n        \n        return self.model(\n            tgt_vec=batch['tgt_vec'],\n            seq_vecs=batch['seq_vecs'],\n            seq_mask=batch['seq_mask'],\n            numerics=batch['numerics'],\n            user_ids=batch['user_ids'],\n            tag_ids=batch['tag_ids'],\n            tag_mask=batch['tag_mask'],\n            likes=batch['likes'],\n            views=batch['views']\n        )\n    \n    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n        device = next(self.model.parameters()).device\n        batch_on_device = {}\n        return self.model(\n            tgt_vec=batch['tgt_vec'],\n            seq_vecs=batch['seq_vecs'],\n            seq_mask=batch['seq_mask'],\n            numerics=batch['numerics'],\n            user_ids=batch['user_ids'],\n            tag_ids=batch['tag_ids'],\n            tag_mask=batch['tag_mask'],\n            likes=batch['likes'],\n            views=batch['views']\n        )\n    \n    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n        logits = self.forward(batch)\n        targets = batch['labels']\n        \n        loss = self.criterion(logits, targets)\n        \n        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n        return loss\n    \n    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n        logits = self.forward(batch)\n        targets = batch['labels']\n        \n        loss = self.criterion(logits, targets)\n        \n        # Pour AUC\n        probs = torch.sigmoid(logits).detach()\n        self.val_targets.extend(targets.cpu().numpy().tolist())\n        self.val_preds.extend(probs.cpu().numpy().tolist())\n        \n        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n        return loss\n    \n    def on_validation_epoch_end(self):\n        if len(self.val_targets) > 0:\n            try:\n                from sklearn.metrics import roc_auc_score\n                auc = roc_auc_score(self.val_targets, self.val_preds)\n                self.log('val_auc', auc, prog_bar=True)\n                \n                print(f\"\\nEpoch {self.current_epoch} - Validation AUC: {auc:.4f}\")\n                \n            except Exception as e:\n                print(f\"Erreur calcul AUC: {e}\")\n                self.log('val_auc', 0.5, prog_bar=True)\n            \n            # R√©initialisation\n            self.val_targets.clear()\n            self.val_preds.clear()\n    \n    def configure_optimizers(self):\n        \"\"\"Optimizer simple (Adam)\"\"\"\n        optimizer = torch.optim.Adam(\n            self.parameters(),\n            lr=self.learning_rate,\n            betas=(0.9, 0.999),\n            eps=1e-8\n        )\n        \n        return optimizer\n    \n    def predict_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n        \"\"\"√âtape de pr√©diction\"\"\"\n        with torch.no_grad():\n            logits = self.forward(batch)\n            probs = torch.sigmoid(logits)\n        return probs\n\n# ==================== UTILITAIRES ====================\ndef create_collate_fn_simple(item_embeddings: torch.Tensor):\n    \"\"\"Fonction de collation simple\"\"\"\n    \n    def collate_fn(batch: List[Dict]):\n        batch_size = len(batch)\n        \n        # R√©cup√©ration des donn√©es\n        tgt_idxs = torch.LongTensor([b['tgt_idx'] for b in batch])\n        user_ids = torch.LongTensor([b['user_id'] for b in batch])\n        likes = torch.LongTensor([b['likes'] for b in batch])\n        views = torch.LongTensor([b['views'] for b in batch])\n        numerics = torch.from_numpy(np.stack([b['numerics'] for b in batch])).float()\n        labels = torch.FloatTensor([b['label'] for b in batch])\n        \n        # S√©quences\n        seq_lengths = [len(b['seq_idxs']) for b in batch]\n        max_seq_len = max(seq_lengths)\n        \n        seq_idxs = torch.zeros(batch_size, max_seq_len, dtype=torch.long)\n        seq_mask = torch.zeros(batch_size, max_seq_len, dtype=torch.bool)\n        \n        for i, b in enumerate(batch):\n            seq_len = len(b['seq_idxs'])\n            seq_idxs[i, :seq_len] = torch.LongTensor(b['seq_idxs'])\n            seq_mask[i, :seq_len] = True\n        \n        # Tags\n        tag_lengths = [len(b['tags']) for b in batch]\n        max_tag_len = max(tag_lengths)\n        \n        tag_ids = torch.zeros(batch_size, max_tag_len, dtype=torch.long)\n        tag_mask = torch.zeros(batch_size, max_tag_len, dtype=torch.bool)\n        \n        for i, b in enumerate(batch):\n            tag_len = len(b['tags'])\n            tag_ids[i, :tag_len] = torch.LongTensor(b['tags'])\n            tag_mask[i, :tag_len] = True\n        \n        # Embeddings (sur CPU pour DataLoader)\n        if item_embeddings.device.type != 'cpu':\n            item_emb_cpu = item_embeddings.cpu()\n        else:\n            item_emb_cpu = item_embeddings\n        \n        tgt_vec = item_emb_cpu[tgt_idxs]\n        seq_vecs = item_emb_cpu[seq_idxs]\n        \n        return {\n            'tgt_vec': tgt_vec,\n            'seq_vecs': seq_vecs,\n            'seq_mask': seq_mask,\n            'numerics': numerics,\n            'labels': labels,\n            'user_ids': user_ids,\n            'tag_ids': tag_ids,\n            'tag_mask': tag_mask,\n            'likes': likes,\n            'views': views\n        }\n    \n    return collate_fn\n\n# ==================== ENTR√âE PRINCIPALE ====================\nif __name__ == \"__main__\":\n    # Test simple du mod√®le\n    config = Config()\n    \n    # Dimensions de test\n    batch_size = 32\n    seq_len = 50\n    item_dim = 128\n    num_users = 1000\n    \n    # Cr√©ation du mod√®le\n    model = ExactCTRModel(\n        item_dim=item_dim,\n        num_users=num_users,\n        config=config\n    )\n    \n    # Donn√©es d'exemple\n    tgt_vec = torch.randn(batch_size, item_dim)\n    seq_vecs = torch.randn(batch_size, seq_len, item_dim)\n    seq_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)\n    numerics = torch.randn(batch_size, 2)\n    user_ids = torch.randint(0, num_users, (batch_size,))\n    tag_ids = torch.randint(0, config.NUM_TAGS, (batch_size, 5))\n    tag_mask = torch.ones(batch_size, 5, dtype=torch.bool)\n    likes = torch.randint(0, config.LIKES_VOCAB, (batch_size,))\n    views = torch.randint(0, config.VIEWS_VOCAB, (batch_size,))\n    \n    # Forward pass\n    logits = model(\n        tgt_vec=tgt_vec,\n        seq_vecs=seq_vecs,\n        seq_mask=seq_mask,\n        numerics=numerics,\n        user_ids=user_ids,\n        tag_ids=tag_ids,\n        tag_mask=tag_mask,\n        likes=likes,\n        views=views\n    )\n    \n    print(f\"‚úì Mod√®le cr√©√© avec succ√®s!\")\n    print(f\"  ‚Ä¢ Input shape: {batch_size} batchs\")\n    print(f\"  ‚Ä¢ Output shape: {logits.shape}\")\n    print(f\"  ‚Ä¢ Architecture v√©rifi√©e ‚úì\")\n    \n    # Compter les param√®tres\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"\\nüìä Statistiques du mod√®le:\")\n    print(f\"  ‚Ä¢ Param√®tres totaux: {total_params:,}\")\n    print(f\"  ‚Ä¢ Param√®tres entra√Ænables: {trainable_params:,}\")\n    \n    # V√©rification de l'architecture\n    print(f\"\\n‚úÖ ARCHITECTURE V√âRIFI√âE:\")\n    print(f\"  1. Embeddings uniformes (64D) ‚úì\")\n    print(f\"  2. Transformer(items + target seulement) ‚úì\")\n    print(f\"  3. Concat avec autres features ‚úì\")\n    print(f\"  4. DCNv2 + DNN parall√®le ‚úì\")\n    print(f\"  5. MLP final ‚úì\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T21:40:56.458647Z","iopub.execute_input":"2025-12-20T21:40:56.459617Z","iopub.status.idle":"2025-12-20T21:40:57.733483Z","shell.execute_reply.started":"2025-12-20T21:40:56.459592Z","shell.execute_reply":"2025-12-20T21:40:57.732622Z"}},"outputs":[{"name":"stdout","text":"‚úì Mod√®le cr√©√© avec succ√®s!\n  ‚Ä¢ Input shape: 32 batchs\n  ‚Ä¢ Output shape: torch.Size([32])\n  ‚Ä¢ Architecture v√©rifi√©e ‚úì\n\nüìä Statistiques du mod√®le:\n  ‚Ä¢ Param√®tres totaux: 77,503,001\n  ‚Ä¢ Param√®tres entra√Ænables: 76,607,513\n\n‚úÖ ARCHITECTURE V√âRIFI√âE:\n  1. Embeddings uniformes (64D) ‚úì\n  2. Transformer(items + target seulement) ‚úì\n  3. Concat avec autres features ‚úì\n  4. DCNv2 + DNN parall√®le ‚úì\n  5. MLP final ‚úì\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport polars as plrs\nfrom torch.utils.data import Dataset\nfrom typing import List, Dict, Optional\nfrom tqdm.auto import tqdm\n\nclass FeatureNormalizer:\n    \"\"\"Normalise les features num√©riques (likes_level, views_level)\"\"\"\n    \n    def __init__(self):\n        self.stats = {}\n    \n    def fit(self, df: plrs.DataFrame, numeric_cols: List[str]):\n        \"\"\"Calcule les statistiques sur le train set\"\"\"\n        for col in numeric_cols:\n            if col in df.columns:\n                mean_val = float(df[col].mean())\n                std_val = float(df[col].std())\n                self.stats[col] = {\n                    'mean': mean_val,\n                    'std': std_val if std_val > 0 else 1.0,\n                    'min': float(df[col].min()),\n                    'max': float(df[col].max())\n                }\n        return self\n    \n    def transform(self, df: plrs.DataFrame):\n        \"\"\"Applique la normalisation standard scaling\"\"\"\n        df_norm = df.clone()\n        for col, stat in self.stats.items():\n            if col in df.columns:\n                df_norm = df_norm.with_columns(\n                    ((plrs.col(col) - stat['mean']) / stat['std']).alias(col)\n                )\n        return df_norm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T21:41:07.275595Z","iopub.execute_input":"2025-12-20T21:41:07.276269Z","iopub.status.idle":"2025-12-20T21:41:07.727821Z","shell.execute_reply.started":"2025-12-20T21:41:07.276244Z","shell.execute_reply":"2025-12-20T21:41:07.727207Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nclass CTRDataset(Dataset):\n    \"\"\"Dataset pour CTR prediction - VERSION EXACTE pour l'architecture\"\"\"\n    \n    def __init__(self, \n                 df: pd.DataFrame, \n                 id2idx: Dict[int, int],\n                 normalizer: Optional[FeatureNormalizer] = None,\n                 max_seq_len: int = 100,\n                 max_tag_len: int = 5,\n                 is_train: bool = True):\n        \n        self.df = df.to_pandas()\n        self.id2idx = id2idx\n        self.normalizer = normalizer\n        self.max_seq_len = max_seq_len\n        self.max_tag_len = max_tag_len\n        self.is_train = is_train\n        \n        # Pr√©-calcul\n        self._preprocess_data()\n    \n    def _preprocess_data(self):\n        \"\"\"Pr√©process les donn√©es pour l'architecture exacte\"\"\"\n        self.processed_data = []\n        \n        for idx in tqdm(range(len(self.df)), desc=\"Preprocessing\"):\n            r = self.df.iloc[idx]\n            \n            # 1. Item target (index)\n            tgt_idx = self.id2idx.get(int(r['item_id']), 0)\n            \n            # 2. S√©quence d'items (pour transformer)\n            seq = r.get('item_seq', [])\n            if isinstance(seq, str):\n                try:\n                    seq = eval(seq)\n                except:\n                    seq = []\n            # Garder les derniers items (ordre chronologique)\n            seq_idxs = [self.id2idx.get(int(i), 0) for i in seq[-self.max_seq_len:]]\n            \n            # 3. Tags (pour embedding simple)\n            tags = r.get('item_tags', [0])\n            if isinstance(tags, str):\n                try:\n                    tags = eval(tags)\n                except:\n                    tags = [0]\n            tags = [int(t) for t in tags[:self.max_tag_len]]\n            \n            # 4. Features cat√©gorielles (pour embeddings)\n            likes = int(r.get('likes_level', 0))\n            views = int(r.get('views_level', 0))\n            \n            # 5. Features num√©riques NORMALIS√âES (pour concat apr√®s transformer)\n            if self.normalizer:\n                # Normalisation standard scaling\n                likes_norm = (float(r.get('likes_level', 0)) - self.normalizer.stats['likes_level']['mean']) / self.normalizer.stats['likes_level']['std']\n                views_norm = (float(r.get('views_level', 0)) - self.normalizer.stats['views_level']['mean']) / self.normalizer.stats['views_level']['std']\n            else:\n                likes_norm = float(r.get('likes_level', 0))\n                views_norm = float(r.get('views_level', 0))\n            \n            numerics = np.array([likes_norm, views_norm], dtype=np.float32)\n            \n            # 6. Label (0 ou 1)\n            label = np.float32(r['label']) if 'label' in r.index else 0.0\n            \n            # 7. User ID (pour embedding)\n            user_id = int(r['user_id'])\n            \n            # Stockage dans le format EXACT pour l'architecture\n            self.processed_data.append({\n                'tgt_idx': tgt_idx,      # Index de l'item target\n                'seq_idxs': seq_idxs,    # S√©quence d'items (pour transformer)\n                'tags': tags,            # Tags (pour embedding simple)\n                'likes': likes,          # Likes level (cat√©goriel, 0-10)\n                'views': views,          # Views level (cat√©goriel, 0-10)\n                'numerics': numerics,    # Features num√©riques normalis√©es\n                'label': label,          # Label binaire\n                'user_id': user_id       # User ID\n            })\n    \n    def __len__(self):\n        return len(self.processed_data)\n    \n    def __getitem__(self, idx):\n        \"\"\"Retourne un √©chantillon - format EXACT pour l'architecture\"\"\"\n        return self.processed_data[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T21:41:12.530356Z","iopub.execute_input":"2025-12-20T21:41:12.530859Z","iopub.status.idle":"2025-12-20T21:41:14.270719Z","shell.execute_reply.started":"2025-12-20T21:41:12.530835Z","shell.execute_reply":"2025-12-20T21:41:14.270110Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T14:10:55.292951Z","iopub.execute_input":"2025-12-20T14:10:55.294265Z","iopub.status.idle":"2025-12-20T14:10:55.302293Z","shell.execute_reply.started":"2025-12-20T14:10:55.294227Z","shell.execute_reply":"2025-12-20T14:10:55.301423Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# train_simple.py\nimport torch\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nimport numpy as np\nimport pandas as pd\nimport polars as plrs\nfrom tqdm.auto import tqdm\n\ndef main():\n    print(\"=\" * 70)\n    print(\"ENTRA√éNEMENT - ARCHITECTURE EXACTE\")\n    print(\"=\" * 70)\n    \n    # Configuration\n    config = Config()\n    \n    # Chemins des donn√©es\n    DATA_PATH = \"/kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/MicroLens_1M_x1\"\n    \n    # 1. Chargement des donn√©es\n    print(\"\\n1. Chargement des donn√©es...\")\n    train_df = plrs.read_parquet(f\"{DATA_PATH}/train.parquet\")\n    valid_df = plrs.read_parquet(f\"{DATA_PATH}/valid.parquet\")\n    test_df = plrs.read_parquet(f\"{DATA_PATH}/test.parquet\")\n    item_info = plrs.read_parquet(f\"{DATA_PATH}/item_info.parquet\")\n    \n    # 2. Normalisation\n    print(\"\\n2. Normalisation...\")\n    normalizer = FeatureNormalizer()\n    normalizer.fit(train_df, ['likes_level', 'views_level'])\n    train_df = normalizer.transform(train_df)\n    valid_df = normalizer.transform(valid_df)\n    test_df = normalizer.transform(test_df)\n    \n    # 3. Pr√©paration embeddings\n    print(\"\\n3. Pr√©paration embeddings...\")\n    all_item_ids = [r['item_id'] for r in item_info.to_dicts()]\n    id2idx = {item_id: idx for idx, item_id in enumerate(all_item_ids)}\n    \n    item_embeddings = torch.from_numpy(\n        np.stack(item_info['item_emb_d128'].to_list())\n    ).float().cpu()\n    \n    # 4. Datasets et DataLoaders\n    print(\"\\n4. Cr√©ation DataLoaders...\")\n    collate_fn = create_collate_fn_simple(item_embeddings)\n    \n    train_dataset = CTRDataset(train_df, id2idx, normalizer)\n    valid_dataset = CTRDataset(valid_df, id2idx, normalizer)\n    test_dataset = CTRDataset(test_df, id2idx, normalizer)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=128,\n        shuffle=True,\n        num_workers=0,\n        collate_fn=collate_fn\n    )\n    \n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=256,\n        shuffle=False,\n        num_workers=0,\n        collate_fn=collate_fn\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=256,\n        shuffle=False,\n        num_workers=0,\n        collate_fn=collate_fn\n    )\n    \n    # 5. Cr√©ation du mod√®le - CORRECTION AJOUT√âE ICI\n    print(\"\\n5. Cr√©ation du mod√®le...\")\n    num_users = int(max(\n        train_df['user_id'].max(),\n        valid_df['user_id'].max(),\n        test_df['user_id'].max()\n    )) + 5000\n    \n    # AJOUT: Calculer les valeurs max pour les autres vocabulaires\n    print(\"  ‚Ä¢ Calcul des vocabulaires...\")\n    \n    # Pour les tags - extraire la valeur max des listes de tags\n    def get_max_tag(df):\n        if 'item_tags' in df.columns:\n            # Extraire toutes les valeurs des listes\n            tags_series = df['item_tags'].explode()\n            return int(tags_series.max()) if tags_series is not None else 0\n        return 0\n    \n    max_tag = max(\n        get_max_tag(train_df),\n        get_max_tag(valid_df),\n        get_max_tag(test_df)\n    ) + 1000  # Marge\n    \n    # Pour likes et views\n    max_like = int(max(\n        train_df['likes_level'].max(),\n        valid_df['likes_level'].max(),\n        test_df['likes_level'].max()\n    )) + 10  # Marge\n    \n    max_view = int(max(\n        train_df['views_level'].max(),\n        valid_df['views_level'].max(),\n        test_df['views_level'].max()\n    )) + 10  # Marge\n    \n    # Mettre √† jour la config\n    config.NUM_TAGS = max_tag\n    config.LIKES_VOCAB = max_like\n    config.VIEWS_VOCAB = max_view\n    \n    print(f\"  ‚Ä¢ Vocabulaires ajust√©s:\")\n    print(f\"    - NUM_TAGS: {config.NUM_TAGS}\")\n    print(f\"    - LIKES_VOCAB: {config.LIKES_VOCAB}\")\n    print(f\"    - VIEWS_VOCAB: {config.VIEWS_VOCAB}\")\n    \n    # Cr√©ation du mod√®le avec les nouvelles valeurs\n    model = ExactCTRModel(\n        item_dim=item_embeddings.shape[1],\n        num_users=num_users,\n        config=config\n    )\n    \n    # AJOUT: Test sur CPU avant GPU\n    print(\"  ‚Ä¢ Test forward sur CPU...\")\n    try:\n        # Prendre un batch de test\n        test_batch = next(iter(train_loader))\n        \n        # Test sur CPU\n        with torch.no_grad():\n            logits = model(\n                tgt_vec=test_batch['tgt_vec'],\n                seq_vecs=test_batch['seq_vecs'],\n                seq_mask=test_batch['seq_mask'],\n                numerics=test_batch['numerics'],\n                user_ids=test_batch['user_ids'],\n                tag_ids=test_batch['tag_ids'],\n                tag_mask=test_batch['tag_mask'],\n                likes=test_batch['likes'],\n                views=test_batch['views']\n            )\n        print(f\"  ‚úì Test forward r√©ussi!\")\n        \n    except Exception as e:\n        print(f\"  ‚úó Erreur lors du test CPU: {e}\")\n        print(\"  ‚Ä¢ V√©rification des valeurs max:\")\n        print(f\"    user_ids max: {test_batch['user_ids'].max().item()}\")\n        print(f\"    tag_ids max: {test_batch['tag_ids'].max().item()}\")\n        print(f\"    likes max: {test_batch['likes'].max().item()}\")\n        print(f\"    views max: {test_batch['views'].max().item()}\")\n        raise\n    \n    # D√©placer sur GPU si disponible\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"  ‚Ä¢ D√©placement sur {device}...\")\n    model = model.to(device)\n    \n    # 6. Lightning Module\n    lightning_model = CTRLightningModule(\n        model=model,\n        learning_rate=config.LR\n    )\n    \n    # 7. Callbacks\n    checkpoint_callback = ModelCheckpoint(\n        monitor='val_auc',\n        mode='max',\n        save_top_k=1,\n        filename='ctr_exact_{epoch:02d}_{val_auc:.4f}'\n    )\n    \n    early_stop_callback = EarlyStopping(\n        monitor='val_auc',\n        mode='max',\n        patience=3,\n        min_delta=0.001\n    )\n    \n    # 8. Trainer - AJOUT: Option de fallback sur CPU si CUDA √©choue\n    try:\n        trainer = pl.Trainer(\n            max_epochs=config.EPOCHS,\n            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n            devices=1,\n            precision='32-true',\n            gradient_clip_val=1.0,\n            callbacks=[checkpoint_callback, early_stop_callback],\n            enable_progress_bar=True,\n            log_every_n_steps=50\n        )\n    except:\n        print(\"  ‚Ä¢ Fallback sur CPU training...\")\n        trainer = pl.Trainer(\n            max_epochs=config.EPOCHS,\n            accelerator='cpu',\n            devices=1,\n            precision='32-true',\n            gradient_clip_val=1.0,\n            callbacks=[checkpoint_callback, early_stop_callback],\n            enable_progress_bar=True,\n            log_every_n_steps=50\n        )\n    \n    # 9. Entra√Ænement\n    print(\"\\n6. D√©but entra√Ænement...\")\n    print(\"=\" * 70)\n    \n    trainer.fit(\n        model=lightning_model,\n        train_dataloaders=train_loader,\n        val_dataloaders=valid_loader\n    )\n    \n    # 10. Pr√©dictions\n    print(\"\\n7. Pr√©dictions...\")\n    lightning_model.model.eval()\n    predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Test predictions\"):\n            # Move to device\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n                    for k, v in batch.items()}\n            \n            # Forward\n            logits = lightning_model.model(\n                tgt_vec=batch['tgt_vec'],\n                seq_vecs=batch['seq_vecs'],\n                seq_mask=batch['seq_mask'],\n                numerics=batch['numerics'],\n                user_ids=batch['user_ids'],\n                tag_ids=batch['tag_ids'],\n                tag_mask=batch['tag_mask'],\n                likes=batch['likes'],\n                views=batch['views']\n            )\n            \n            probs = torch.sigmoid(logits)\n            predictions.extend(probs.cpu().numpy().tolist())\n    \n    # 11. Sauvegarde\n    submission = pd.DataFrame({\n        'user_id': test_df['user_id'].to_list(),\n        'item_id': test_df['item_id'].to_list(),\n        'prediction': predictions\n    })\n    \n    submission.to_csv('submission_exact.csv', index=False)\n    \n    print(f\"\\n‚úÖ Fichier sauvegard√©: submission_exact.csv\")\n    print(f\"üìä AUC estim√©: {checkpoint_callback.best_model_score:.4f}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T21:41:20.099558Z","iopub.execute_input":"2025-12-20T21:41:20.100033Z","iopub.status.idle":"2025-12-20T21:41:35.449468Z","shell.execute_reply.started":"2025-12-20T21:41:20.100011Z","shell.execute_reply":"2025-12-20T21:41:35.448516Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nENTRA√éNEMENT - ARCHITECTURE EXACTE\n======================================================================\n\n1. Chargement des donn√©es...\n\n2. Normalisation...\n\n3. Pr√©paration embeddings...\n\n4. Cr√©ation DataLoaders...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Preprocessing:   0%|          | 0/3600000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c32b977a56844fdea60a9443b6e742d2"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2972770256.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_47/2972770256.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_collate_fn_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTRDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTRDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTRDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1437587027.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, id2idx, normalizer, max_seq_len, max_tag_len, is_train)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Pr√©-calcul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/1437587027.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m# Normalisation standard scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mlikes_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'likes_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likes_level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'likes_level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mviews_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'views_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'views_level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'views_level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mlikes_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'likes_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Force le debug CUDA\n\n# Ajoutez au d√©but de main()\nprint(\"Debug CUDA activ√©...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T12:51:15.106751Z","iopub.execute_input":"2025-12-20T12:51:15.107452Z","iopub.status.idle":"2025-12-20T12:51:15.111582Z","shell.execute_reply.started":"2025-12-20T12:51:15.107428Z","shell.execute_reply":"2025-12-20T12:51:15.110810Z"}},"outputs":[{"name":"stdout","text":"Debug CUDA activ√©...\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# train_simple.py\nimport os\nimport torch\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nimport numpy as np\nimport pandas as pd\nimport polars as plrs\nfrom tqdm.auto import tqdm\n\ndef main():\n    print(\"=\" * 70)\n    print(\"ENTRA√éNEMENT - ARCHITECTURE EXACTE\")\n    print(\"=\" * 70)\n    \n    # Configuration\n    config = Config()\n    \n    # Chemins des donn√©es\n    DATA_PATH = \"/kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/MicroLens_1M_x1\"\n    \n    # 1. Chargement des donn√©es\n    print(\"\\n1. Chargement des donn√©es...\")\n    train_df = plrs.read_parquet(f\"{DATA_PATH}/train.parquet\")\n    valid_df = plrs.read_parquet(f\"{DATA_PATH}/valid.parquet\")\n    test_df = plrs.read_parquet(f\"{DATA_PATH}/test.parquet\")\n    item_info = plrs.read_parquet(f\"{DATA_PATH}/item_info.parquet\")\n    \n    # 2. Normalisation\n    print(\"\\n2. Normalisation...\")\n    normalizer = FeatureNormalizer()\n    normalizer.fit(train_df, ['likes_level', 'views_level'])\n    train_df = normalizer.transform(train_df)\n    valid_df = normalizer.transform(valid_df)\n    test_df = normalizer.transform(test_df)\n    \n    # 3. Pr√©paration embeddings\n    print(\"\\n3. Pr√©paration embeddings...\")\n    all_item_ids = [r['item_id'] for r in item_info.to_dicts()]\n    id2idx = {item_id: idx for idx, item_id in enumerate(all_item_ids)}\n    \n    item_embeddings = torch.from_numpy(\n        np.stack(item_info['item_emb_d128'].to_list())\n    ).float().cpu()\n    \n    # 4. Datasets et DataLoaders\n    print(\"\\n4. Cr√©ation DataLoaders...\")\n    collate_fn = create_collate_fn_simple(item_embeddings)\n    \n    train_dataset = CTRDataset(train_df, id2idx, normalizer)\n    valid_dataset = CTRDataset(valid_df, id2idx, normalizer)\n    test_dataset = CTRDataset(test_df, id2idx, normalizer)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=128,\n        shuffle=True,\n        num_workers=0,\n        collate_fn=collate_fn\n    )\n    \n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=256,\n        shuffle=False,\n        num_workers=0,\n        collate_fn=collate_fn\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=256,\n        shuffle=False,\n        num_workers=0,\n        collate_fn=collate_fn\n    )\n    \n    # 5. Cr√©ation du mod√®le - CORRECTION AJOUT√âE ICI\n    print(\"\\n5. Cr√©ation du mod√®le...\")\n    num_users = int(max(\n        train_df['user_id'].max(),\n        valid_df['user_id'].max(),\n        test_df['user_id'].max()\n    )) + 5000\n    \n    # AJOUT: Calculer les valeurs max pour les autres vocabulaires\n    print(\"  ‚Ä¢ Calcul des vocabulaires...\")\n    \n    # Pour les tags - extraire la valeur max des listes de tags\n    def get_max_tag(df):\n        if 'item_tags' in df.columns:\n            tags_series = df['item_tags'].explode()\n            return int(tags_series.max()) if tags_series is not None else 0\n        return 0\n    \n    max_tag = max(\n        get_max_tag(train_df),\n        get_max_tag(valid_df),\n        get_max_tag(test_df)\n    ) + 1000  # Marge\n    \n    # Pour likes et views\n    max_like = int(max(\n        train_df['likes_level'].max(),\n        valid_df['likes_level'].max(),\n        test_df['likes_level'].max()\n    )) + 10  # Marge\n    \n    max_view = int(max(\n        train_df['views_level'].max(),\n        valid_df['views_level'].max(),\n        test_df['views_level'].max()\n    )) + 10  # Marge\n    \n    # Mettre √† jour la config\n    config.NUM_TAGS = max_tag\n    config.LIKES_VOCAB = max_like\n    config.VIEWS_VOCAB = max_view\n    \n    print(f\"  ‚Ä¢ Vocabulaires ajust√©s:\")\n    print(f\"    - NUM_TAGS: {config.NUM_TAGS}\")\n    print(f\"    - LIKES_VOCAB: {config.LIKES_VOCAB}\")\n    print(f\"    - VIEWS_VOCAB: {config.VIEWS_VOCAB}\")\n    \n    # Cr√©ation du mod√®le avec les nouvelles valeurs\n    model = ExactCTRModel(\n        item_dim=item_embeddings.shape[1],\n        num_users=num_users,\n        config=config\n    )\n    \n    # AJOUT: Test sur CPU avant GPU\n    print(\"  ‚Ä¢ Test forward sur CPU...\")\n    try:\n        test_batch = next(iter(train_loader))\n        with torch.no_grad():\n            logits = model(\n                tgt_vec=test_batch['tgt_vec'],\n                seq_vecs=test_batch['seq_vecs'],\n                seq_mask=test_batch['seq_mask'],\n                numerics=test_batch['numerics'],\n                user_ids=test_batch['user_ids'],\n                tag_ids=test_batch['tag_ids'],\n                tag_mask=test_batch['tag_mask'],\n                likes=test_batch['likes'],\n                views=test_batch['views']\n            )\n        print(f\"  ‚úì Test forward r√©ussi!\")\n    except Exception as e:\n        print(f\"  ‚úó Erreur lors du test CPU: {e}\")\n        raise\n    \n    # D√©placer sur GPU si disponible\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"  ‚Ä¢ D√©placement sur {device}...\")\n    model = model.to(device)\n    \n    # 6. Lightning Module\n    lightning_model = CTRLightningModule(\n        model=model,\n        learning_rate=config.LR\n    )\n    \n    # 7. Callbacks\n    checkpoint_callback = ModelCheckpoint(\n        monitor='val_auc',\n        mode='max',\n        save_top_k=1,\n        filename='ctr_exact_{epoch:02d}_{val_auc:.4f}'\n    )\n    \n    early_stop_callback = EarlyStopping(\n        monitor='val_auc',\n        mode='max',\n        patience=3,\n        min_delta=0.001\n    )\n    \n    # === üîÅ OPTION : reprise depuis un checkpoint pr√©c√©dent ===\n    resume_checkpoint = None\n    ckpt_dir = \"/kaggle/working/lightning_logs/version_4/checkpoints\"\n    if os.path.exists(ckpt_dir):\n        ckpts = [os.path.join(ckpt_dir, f) for f in os.listdir(ckpt_dir) if f.endswith(\".ckpt\")]\n        if len(ckpts) > 0:\n            resume_checkpoint = max(ckpts, key=os.path.getmtime)\n            print(f\"  ‚Ä¢ Reprise depuis le checkpoint : {resume_checkpoint}\")\n            config.EPOCHS += 10\n        else:\n            print(\"  ‚Ä¢ Aucun checkpoint trouv√©, entra√Ænement depuis z√©ro.\")\n    else:\n        print(\"  ‚Ä¢ Aucun checkpoint trouv√©, entra√Ænement depuis z√©ro.\")\n    \n    # 8. Trainer\n    try:\n        trainer = pl.Trainer(\n            max_epochs=config.EPOCHS,\n            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n            devices=1,\n            precision='32-true',\n            gradient_clip_val=1.0,\n            callbacks=[checkpoint_callback, early_stop_callback],\n            enable_progress_bar=True,\n            log_every_n_steps=50\n        )\n    except:\n        print(\"  ‚Ä¢ Fallback sur CPU training...\")\n        trainer = pl.Trainer(\n            max_epochs=config.EPOCHS,\n            accelerator='cpu',\n            devices=1,\n            precision='32-true',\n            gradient_clip_val=1.0,\n            callbacks=[checkpoint_callback, early_stop_callback],\n            enable_progress_bar=True,\n            log_every_n_steps=50,\n            resume_from_checkpoint=resume_checkpoint\n        )\n    \n    # 9. Entra√Ænement\n    print(\"\\n6. D√©but entra√Ænement...\")\n    print(\"=\" * 70)\n    \n    trainer.fit(\n        model=lightning_model,\n        train_dataloaders=train_loader,\n        val_dataloaders=valid_loader,\n        ckpt_path=resume_checkpoint\n    )\n    \n    # 10. Pr√©dictions\n    print(\"\\n7. Pr√©dictions...\")\n    lightning_model.model.eval()\n    predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Test predictions\"):\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n                    for k, v in batch.items()}\n            logits = lightning_model.model(\n                tgt_vec=batch['tgt_vec'],\n                seq_vecs=batch['seq_vecs'],\n                seq_mask=batch['seq_mask'],\n                numerics=batch['numerics'],\n                user_ids=batch['user_ids'],\n                tag_ids=batch['tag_ids'],\n                tag_mask=batch['tag_mask'],\n                likes=batch['likes'],\n                views=batch['views']\n            )\n            probs = torch.sigmoid(logits)\n            predictions.extend(probs.cpu().numpy().tolist())\n    \n    # 11. Sauvegarde\n    submission = pd.DataFrame({\n        'user_id': test_df['user_id'].to_list(),\n        'item_id': test_df['item_id'].to_list(),\n        'prediction': predictions\n    })\n    \n    submission.to_csv('submission_exact.csv', index=False)\n    \n    print(f\"\\n‚úÖ Fichier sauvegard√©: submission_exact.csv\")\n    print(f\"üìä AUC estim√©: {checkpoint_callback.best_model_score:.4f}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T19:39:38.092649Z","iopub.execute_input":"2025-12-20T19:39:38.093535Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nENTRA√éNEMENT - ARCHITECTURE EXACTE\n======================================================================\n\n1. Chargement des donn√©es...\n\n2. Normalisation...\n\n3. Pr√©paration embeddings...\n\n4. Cr√©ation DataLoaders...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Preprocessing:   0%|          | 0/3600000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc89c75a5326494db91e0c5d857f9e2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Preprocessing:   0%|          | 0/10000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65c87e07e6843d2b0bf966aceeef006"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Preprocessing:   0%|          | 0/379142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9044b16b52354eeca706bdc295aa5525"}},"metadata":{}},{"name":"stdout","text":"\n5. Cr√©ation du mod√®le...\n  ‚Ä¢ Calcul des vocabulaires...\n  ‚Ä¢ Vocabulaires ajust√©s:\n    - NUM_TAGS: 1000\n    - LIKES_VOCAB: 11\n    - VIEWS_VOCAB: 11\n  ‚Ä¢ Test forward sur CPU...\n","output_type":"stream"},{"name":"stderr","text":"GPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n","output_type":"stream"},{"name":"stdout","text":"  ‚úì Test forward r√©ussi!\n  ‚Ä¢ D√©placement sur cuda...\n  ‚Ä¢ Reprise depuis le checkpoint : /kaggle/working/lightning_logs/version_4/checkpoints/ctr_exact_epoch=06_val_auc=0.7077.ckpt\n\n6. D√©but entra√Ænement...\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"Restoring states from the checkpoint path at /kaggle/working/lightning_logs/version_4/checkpoints/ctr_exact_epoch=06_val_auc=0.7077.ckpt\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:445: The dirpath has changed from '/kaggle/working/lightning_logs/version_4/checkpoints' to '/kaggle/working/lightning_logs/version_5/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name      | Type              | Params | Mode \n--------------------------------------------------------\n0 | model     | ExactCTRModel     | 141 M  | train\n1 | criterion | BCEWithLogitsLoss | 0      | train\n--------------------------------------------------------\n76.6 M    Trainable params\n64.4 M    Non-trainable params\n141 M     Total params\n564.028   Total estimated model params size (MB)\n84        Modules in train mode\n0         Modules in eval mode\nRestored all states from the checkpoint at /kaggle/working/lightning_logs/version_4/checkpoints/ctr_exact_epoch=06_val_auc=0.7077.ckpt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 6 - Validation AUC: 0.7044\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"946811ba42374be1b1a5b6f2437cf7eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 7 - Validation AUC: 0.7199\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 8 - Validation AUC: 0.7273\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 9 - Validation AUC: 0.7365\n","output_type":"stream"}],"execution_count":null}]}